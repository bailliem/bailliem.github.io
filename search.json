[
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "About",
    "section": "",
    "text": "Statistician working in Pharma."
  },
  {
    "objectID": "posts/saps/saps.html",
    "href": "posts/saps/saps.html",
    "title": "Analysis plans",
    "section": "",
    "text": "To outline analyses in a way that ensures feasibility, addressing scientific objectives, resource availability, necessary reviews, and realistic timelines. The focus is on secondary analysis of data.\n\n\n\nAn analysis plan is a blueprint for your research journey. It’s not just a roadmap; it’s a living document that evolves with your project. It helps you:\n\nOrganize Thoughts: Distill broad research questions into actionable steps.\nFacilitate Communication: Clearly convey your plan to stakeholders for timely feedback.\nJustify Approach: Explain your analytical choices and adapt as needed.\nDocument History: Record the evolution of your thinking and methods.\n\n\n\n\nImagine you’re researching the impact of a new drug. Your analysis plan starts broad - you want to see if the drug works. As you delve deeper, you discover specific areas to focus on, like dosage effectiveness and patient age groups. Your plan evolves, documenting these shifts and the reasons behind them.\n\n\n\nMoving from high-level goals to concrete tasks, an analysis plan encourages critical thinking and discussion. It’s not about rigid pre-specification; it’s about guiding your exploration and ensuring you don’t miss crucial steps.\n\n\n\n\nProblem: Define your research question. Keep refining it as new information emerges.\nPlan: Develop a strategy that aligns with your problem statement.\nData: Ensure your data matches your question and chosen methods.\nAnalysis: Use the data to address your problem.\nConclusion: Summarize findings in relatable terms and discuss the strengths and weaknesses of your approach.\n\n\n\n\nIn our drug research example, the Problem is determining drug efficacy. The Plan includes trials with varied dosages. Data involves collecting trial results. Analysis involves statistical testing for efficacy. The Conclusion is a clear statement of the drug’s effectiveness.\n\n\n\n\nTeam Collaboration: Discuss objectives and methodologies early. Assign roles and tasks for efficient workflow.\nKnowledge Sharing: Documenting your plan aids in transferring knowledge within your team, especially from senior to junior members.\nQuality Control: The planning process itself acts as a checkpoint for ensuring research integrity.\n\n\n\n\nLeverage Git for version control and GitLab for task management. Break down your plan into ‘issues’ or tasks, each handled in a separate branch. Merge back into the main branch upon completion after peer review.\n\n\n\n\nRisk Management: Identify potential risks like data unavailability or methodological limitations and plan mitigations.\nEthical Considerations: Ensure data privacy and compliance with ethical standards, especially in sensitive projects like clinical trials.\n\n\n\n\nPost-analysis, evaluate your approach against set metrics. Reflect on what worked and what could be improved for future projects.\n\n\n\nYour analysis plan is more than a set of tasks; it’s the backbone of your research project. It guides you, evolves with your project, and ensures you stay on track while maintaining research integrity and effectiveness."
  },
  {
    "objectID": "posts/saps/saps.html#analysis-plan-guide-revised-draft",
    "href": "posts/saps/saps.html#analysis-plan-guide-revised-draft",
    "title": "Analysis plans",
    "section": "",
    "text": "To outline analyses in a way that ensures feasibility, addressing scientific objectives, resource availability, necessary reviews, and realistic timelines. The focus is on secondary analysis of data.\n\n\n\nAn analysis plan is a blueprint for your research journey. It’s not just a roadmap; it’s a living document that evolves with your project. It helps you:\n\nOrganize Thoughts: Distill broad research questions into actionable steps.\nFacilitate Communication: Clearly convey your plan to stakeholders for timely feedback.\nJustify Approach: Explain your analytical choices and adapt as needed.\nDocument History: Record the evolution of your thinking and methods.\n\n\n\n\nImagine you’re researching the impact of a new drug. Your analysis plan starts broad - you want to see if the drug works. As you delve deeper, you discover specific areas to focus on, like dosage effectiveness and patient age groups. Your plan evolves, documenting these shifts and the reasons behind them.\n\n\n\nMoving from high-level goals to concrete tasks, an analysis plan encourages critical thinking and discussion. It’s not about rigid pre-specification; it’s about guiding your exploration and ensuring you don’t miss crucial steps.\n\n\n\n\nProblem: Define your research question. Keep refining it as new information emerges.\nPlan: Develop a strategy that aligns with your problem statement.\nData: Ensure your data matches your question and chosen methods.\nAnalysis: Use the data to address your problem.\nConclusion: Summarize findings in relatable terms and discuss the strengths and weaknesses of your approach.\n\n\n\n\nIn our drug research example, the Problem is determining drug efficacy. The Plan includes trials with varied dosages. Data involves collecting trial results. Analysis involves statistical testing for efficacy. The Conclusion is a clear statement of the drug’s effectiveness.\n\n\n\n\nTeam Collaboration: Discuss objectives and methodologies early. Assign roles and tasks for efficient workflow.\nKnowledge Sharing: Documenting your plan aids in transferring knowledge within your team, especially from senior to junior members.\nQuality Control: The planning process itself acts as a checkpoint for ensuring research integrity.\n\n\n\n\nLeverage Git for version control and GitLab for task management. Break down your plan into ‘issues’ or tasks, each handled in a separate branch. Merge back into the main branch upon completion after peer review.\n\n\n\n\nRisk Management: Identify potential risks like data unavailability or methodological limitations and plan mitigations.\nEthical Considerations: Ensure data privacy and compliance with ethical standards, especially in sensitive projects like clinical trials.\n\n\n\n\nPost-analysis, evaluate your approach against set metrics. Reflect on what worked and what could be improved for future projects.\n\n\n\nYour analysis plan is more than a set of tasks; it’s the backbone of your research project. It guides you, evolves with your project, and ensures you stay on track while maintaining research integrity and effectiveness."
  },
  {
    "objectID": "posts/saps/saps.html#appendix",
    "href": "posts/saps/saps.html#appendix",
    "title": "Analysis plans",
    "section": "Appendix",
    "text": "Appendix"
  },
  {
    "objectID": "posts/vis-lessons/index.html",
    "href": "posts/vis-lessons/index.html",
    "title": "Lessons from a company wide data visualization initiative",
    "section": "",
    "text": "meeting overview\nflyer\nslides"
  },
  {
    "objectID": "posts/caps/caps.html",
    "href": "posts/caps/caps.html",
    "title": "Stop shouting and turn off the caps lock",
    "section": "",
    "text": "It’s never fun to recieve an “ALL CAPS” email. It’s the internet equivalent of being shouted at. And like that typed email written with the caps lock button on, many graphs generate the same feeling.\nWHEN ALL THE WORDS ARE CAPITALIZED, every word is emphasised. Similarly, when ALL your data is displayed by the same bold visual representation, your chart could be shouting at your readers.\nSpaghetti plots are one of the common offenders - a typical culprit displays bold lines over time. In the example below, each line represents an individual patient time course as measured in a clinical trial. For good measure, additional dots are also used to display the observed measurements.\n\n\n\n\n\nYou may be lucky and avoid shouting at your chart consumers if you only have a small volume of data. But soon enough, more data will arrive, and then the shouting begins.\nSome graphical solutions to switching off the CAPS LOCK are to use lighter colours and tones, thinner lines, remove the symbols, …\n\n\n\n\n\n… and the secret weapon: transparency.\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nBy changing the patient lines from black to light gray, reducing the width of the line, removing unnecessary symbols, we can dial down the volume from an 11 to a moderate 3 or 4.\n\n\n\n\n\nAnd we can quieten down the shouting further by using transparency to push the lines into the background.\nThese similar steps give us some breathing space to give a voice to the data we want to emphasise. For example, we may want to highlight a treatment average, a difference or in this example draw attention to a patient of interest. By dialing back the volume, we can then use bolder colours, thicker lines and less transparency to highlight information we want to make louder.\nSo next time you are producing a graph, think about keeping your finger off that CAPS LOCK."
  },
  {
    "objectID": "posts/modern-tools/modern-dmc.html",
    "href": "posts/modern-tools/modern-dmc.html",
    "title": "Don’t we just need to have more visualisations?",
    "section": "",
    "text": "In 1945, Vanveer Bush (Bush, 1945) wrote the visionary article \"As we may think\". In it he described the Memex; a futuristic system for navigating, recognizing patterns, sensemaking, drawing new connections and discoveries from disparate information sources. His vision of the Memex system was one that would enhance scientific and technical work through the linking and connecting information to support the tasks of navigation and sensemaking. In essence, a tool for addressing \"information overload\".\nBush spells out the challenges with too much information (the forest) and the need to devise efficient mechanisms to control and channel information for effective use (to see the trees). The essay is a comment on the importance of managing information to support tasks for answering questions, using the metaphor of an “information explosion” arising from the unprecedented demands on scientific production and technological application during World War II. In effect, Bush outlined the discipline of information science; the practice of scientific and technical knowledge management.\nThe essay influenced new advances such as digitisation of information (digital documents), hyperlinked networks of information (i.e. internet and world wide web), personal computers, computer filing systems, human computer interaction, visual displays, and so on.\nThe problems of information overload, or information explosion, are the same problems we witness in the context of clinical data review and sensemaking that a DMC is tasked with, or teams that have to review clinical study reports and submission dossiers,\nQuoting (Wildfire et al, 2018) \"sheer volume of data reported threatens to lose clinically relevant signals\".\nQuoting (Muetze and Friede, 2020) \"The graphical and interactive visualization of data may ease the exploration of the data and enhance the readers' understanding of the data [..]. DMC reports are no exception to this.\"\nQuoting (Buhr et al.): \"Many ISRGs include so much information in so disorganized a manner that the IDMC is overwhelmed with unnecessary and irrelevant detail; even well-organized minutiae can jeopardize comprehensibility if high-level summaries are lacking. The IDMC report must facilitate efficient review of comprehensive data through a well-designed report structure and thoughtful organization of analyses.\"\nNow, in the year 2020, we are proposing that the critical function of DSMB (as standard), provide comprehensive digital visual displays of linked quantitative information supported by intuitive (human-computer) interaction (search, query, browse, select, link, compare) to facilitate navigation and sensemaking of vital information to answer key questions. Any standalone pre-defined report will need to be supplemented as not all questions will be known in advance, and only emerge during the review process. Future reports and/or systems should be designed for this key information seeking task.\nAre we asking for too much?\nTo answer this question, we take a closer examination of what is possible now, with a specific focus on what advances in statistics, visual analytics, information science, HCI can be used to support the aims of a DMC (to identify any potential safety signals under [time, information, uncertainty, etc.] constraints) and within that task, how visual displays can be defined to answer questions to support that overall aim.\n\n\nThe use of appropriate statistical graphics is essential, from formulating the research question, initial data analysis, execution of the analysis plan, through to communicating results, recommendations and conclusions. We must not only \"get the question right\" (understand contextual subject matter) and \"get the methods right\" (technical expertise) but also \"get the message right (clear reporting).\" This is a core competency for all quantitative work.\nA lot of ground has been covered on this theme from Tukey, Tufte and Cleveland, Harrell, collaborative initiatives such as CTSpedia (https://www.ctspedia.org/do/view/CTSpedia) and PSI SIG VIS (https://www.psiweb.org/sigs-special-interest-groups/visualisation) to guidelines and recommendations [Vickers et al, 2020] and [Pocock et al 2006?, Morris et al. 2019], through to flexible tools to support statistical graphics (https://ggplot2.tidyverse.org/). However, traditional university and professional training curricula have not placed a lot of focus on effective application [Doumont]. Many researchers have to learn on the job through trial and error. This often leads to poor practice [Gordon and Finch] or the avoidance of graphics [Gelman et al.].\nWhy is this important? The role of visual displays are to ensure that relevant information (concepts, assumptions, patterns, trends, signals, and conclusions) are clearly presented and easy to interpret [Chatfield, 2002]. For this, we must understand the laws and principles of effective visual communication, such as the grammar of a (visual) language [Wilkinson]. Visualisation is more than “plotting data”; it can lead to a deeper understanding and inform next steps.\nUsing a single example to demonstrate that often the use of appropriate graphics is one of knowledge translation and assimilation, we focus on the bar charts; a commonly used graph type in medical research. Numerous articles have both demonstrated the pitfalls of using bar charts (and their extension the dynamite chart) [Clelevand, Heer, Tufte, Harrell, Vickers, Weissgerber, Vandermulebrucke], in one instance leading to a policy restricting the use of dynamite charts [http://biostat.mc.vanderbilt.edu/wiki/Main/StatisticalPolicy]. More appropriate alternatives have been advocated such as the dot plot (Clelevand, Heer, Tufte, Harrell, Wessenberger, Vandemeulebroucke 2019…). The bars often take up real estate within a chart without conveying useful information. This can also introduce clutter, hide data and sample size information, make it difficult to introduce measures of uncertainty, and also draws the eye towards false baselines. Cleveland and McGill, and follow up studies such as Heer et al. have also empirically demonstrated that dot plots are more precise for specific visual analytic tasks. Weissgerber(2015) has also demonstrated the issues from a reproducibility perspective. However, in spite of this available knowledge, the translation into standard practice has not always been achieved, with the use of barcharts and dynamite plots amongst other issues are still common (Weissgerber, 2019).\n\n\n\nThe influence of the Memex can be seen in the development of computerised systems to support (exploratory) data analysis. An incomplete timeline of statistical graphics to support exploratory data analysis have existed for a while and continuously are being improved and extended.\n\nIn 1973 the PRIM-9 system available (Tukey at al. 1973 - http://stat-graphics.org/movies/prim9.html),\n1983 Becker et al. introduced SPLOM (Becker et al.) an approach to display a matrix of scatter plots to display multivariate relationships between various measurements,\n1999 Ggobi (Swayne et al. 1999),\nMANET and Mondrian,\nStatistical programming language such as S (Chambers et al) and the follow on R (Iha)\nCorporate solutions such as SAS, Stata, etc.\n\n\n\nModern point and click graphical tools such as Spotfire, Tableau, Qlik\nWeb based applications such as Shiny to develop, bespoke, ad hoc point and click solutions\nReproducible notebooks and documents such as R markdown , Jupyter\n\nOutside of statistics and data analysis tools, we have at our disposal other technologies.\n\nStandard digital document readers such as Adobe Acrobat which have options to search (for keywords) and browse across table contents, pages, page numbering, etc.\nPDF digital documents can have hyperlinks to internal and external references.\nWe also have interactive documentation formats such as html, markdown, bookdown, javascript, which further facilitate interaction.\nJavascript libraries such as D3.js, React.js, etc.\nWe have convenient javascript wrappers to simplify the development of web based applications like shiny and plotly.\n\n\n\n\nAs stated, the problem it seems is not just one of introducing better structured reports or more visual displays. It is also not one of tool availability. It is also not the availability of literature and knowledge on information seeking, visual analytics and effective statistical graphics; see the following comprehensive reviews and overviews in these disciplines (Munzer 2014, Hullman 2019, Vanderplas, Cook and Hofmann 2020 ……..).\nThere is an element of knowledge translation and assimilation. But we should also be mindful that more interactivity and more visuals today may become tomorrow’s problem. Introducing interactivity and more visual displays thoughtlessly will not be a panacea. On the perils of interaction, as Wang et al. highlight: \"We have observed some visual designers getting carried away with packages that contain many interactivities and features, which left reviewers overwhelmed\". And on the quality of visual display quality, we refer to Gordon and Finch (2014): \"Statistician heal thyself: have we lost the plot?\", for an empirical assessment on the quality of visual displays in scientific journals.\nA recent set of papers highlight the crux of the problem and point to a future direction. Focusing on clinical data review, we also have numerous examples of this applied in practice, especially on the focus of clinical safety data review (Wang et al. 2020a, Wang et al. 2020b, Wildfire 2018, Muetze and Friede, 2020).\nWang et al. 2020a outline how interactive visual displays could support safety review. Safety reviews are iterative switching from overview to details. Wildfire et al. 2018 present an overview of a safety explorer suite. This is a collection of tools for the review of clinical trial safety developed in javascript (www.javascript.com) based visualisation libraries such as D3.js (Bostock et al., 2011).\nThis collection of papers utilize interactive data visualisation tools or interactive reports designed for this purpose (safety review). The modules contain a mixture of interactive functionality such as selecting, filtering, sorting and linking. Extending the work of Wildfire, Muetze 2020 described how this interactive suite of tools could supplement safety review for a COVID DMC.\nThese publications show promise, but what is going on here beyond more visual displays and introducing interactivity? What is going on is an implicit recognition that the task of the DMC is one of a collaborative, question and answer, information seeking, pattern identification / recognition and dialogue to identify emerging safety signals. They are applied examples of the information seeking mantra in action (Shneiderman, (1996) \"Overview first, zoom and filter, then details-on-demand\".\n\n\n\nThe DMC requires both a report (overview) and flexibility (zoom and filter, then details on demand) to further navigate available data (information). That is, there is an implicit recognition that the task at hand is not supported completely by a static, pre-specified report that standard DMC reports were designed for. Further clues can be found in the literature such as Bohr, with appeals for teams to be flexible, reports to evolve over the course of a study, for all data to be available, but to balance \"information overload\".\nFrom Buhr: \"Effective and efficient responsiveness to IDMC reporting needs is best addressed by an ISRG that combines expertise in statistics and programming, collaborates with sponsor and IDMC clinicians to develop an adequate clinical understanding of the trial, and maintains flexibility to modify the IDMC report content on an ongoing basis to respond to requests from the IDMC as they arise.\"\nAs Wang et al, 2020b, state - the design process should \"puting end-user needs first\".\nTherefore, what we need are solutions that reflect this task. The purpose (why) to ensure there are no emerging safety signals, to exhaustively explore the available data to ensure no signals exist, and to provide recommendations on next actions (to carry on, to stop, to adapt, etc.) i.e. the task. A successful DMC (the users) review can then be measured by whether the team has confidently made an informed decision that a signal(s) exists or not by addressing a series of predefined or ad-hoc questions. That no signals have been missed or overlooked. Task success can be evaluated by how teams navigate information, fostering collaboration with DMC members to arrive at a common understanding.\nThis revelation gets to the heart of the problem; that is, DMC reports are not designed to support the task of the DMC. The roles of the DMC are both as reviewers and detectives. The report should help the DMC answer the main questions to understand if there are emerging safety signals. Questions such as:\n\nIs there an imbalance?\nWas it already there at baseline?\nDoes it show meaningful relations across parameters/domains?\n\nOften the review generates more questions that have not been captured in the report (Buhr et al. ). In other words, the report is not designed to follow the workflow of the reviewers (the DMC members) within the closed session.\nDMC reports and the data displayed within are not designed to answer the questions the DMC may ask, those of signal detection. Standard DMC reports are often designed to display how data was collected and organized in the database. This is irrelevant to the DMC.\nOften displays are picked from the statistical analysis plan (SAP) tables, listings and figures (TFLs) which are geared toward a different purpose (if at all). In addition, the format and aesthetics are often not pleasing (ugly and/or not enough figures, poorly designed tables, etc). To compound the problems faced by DMC reviewers further, reports may not be structured, may not have a table of contents, outputs may have obscure identifiers such as T001.rtf, pages may not be numbered, etc (see Wittes, Buhr, etc. for further details).\nThe purpose of a DMC report is different to that of a clinical study report. As common place, DMC reports however follow a minimal structure which mimics that of an abbreviated clinical study report appendix. Disposition, demographics, safety (AEs, labs, commends, etc.). TLFs of descriptive statistics by domain and measurement dominate sprinkled potentially with some graphics. Depending on the study design, tables may cover many pages, treatment arms may also paginate across many pages. Therefore the detective work becomes more challenging, as comparisons have to be made across pages both for timepoints, parameters, and possibly treatment comparisons.\nA clinical study report is designed to provide a comprehensive overview of the final completed study. A DMC report is also different from the array of regulatory documents for a dossier to demonstrate efficacy and safety for a regulatory filing. The purpose of the CSR or dossier is to provide a complete, accurate and transparent summary of the compound and study. The study will typically be complete, the data cleaned, and sufficient analysis by the study team familiar with the study is complete.\nAlternatively for the DMC, the study is ongoing, often the data is a mixture of cleaned and uncleaned at the time of the DMC. A data cut will occur to clean data as far as possible, but to ensure the latest information is available, often additional data that has not gone through a cleaning process could be included.\nAlso, throughout the lifecycle of the DMC, new data is added for each DMC. More information is added for each meeting. This aspect is also important for identifying emerging trends.\nTo go back to the purpose of the DMC report, it is for the detection and identification of emerging safety throughout the lifecycle of a study. The report should facilitate this detective work.\nTherefore, by putting the user, the DMC, at the heart of the design, what could an intuitive, interactive, fit for purpose dmc report look like? What components and parts exist now, and what do we need to develop?"
  },
  {
    "objectID": "posts/modern-tools/modern-dmc.html#display-data-to-answer-questions",
    "href": "posts/modern-tools/modern-dmc.html#display-data-to-answer-questions",
    "title": "Don’t we just need to have more visualisations?",
    "section": "",
    "text": "In 1945, Vanveer Bush (Bush, 1945) wrote the visionary article \"As we may think\". In it he described the Memex; a futuristic system for navigating, recognizing patterns, sensemaking, drawing new connections and discoveries from disparate information sources. His vision of the Memex system was one that would enhance scientific and technical work through the linking and connecting information to support the tasks of navigation and sensemaking. In essence, a tool for addressing \"information overload\".\nBush spells out the challenges with too much information (the forest) and the need to devise efficient mechanisms to control and channel information for effective use (to see the trees). The essay is a comment on the importance of managing information to support tasks for answering questions, using the metaphor of an “information explosion” arising from the unprecedented demands on scientific production and technological application during World War II. In effect, Bush outlined the discipline of information science; the practice of scientific and technical knowledge management.\nThe essay influenced new advances such as digitisation of information (digital documents), hyperlinked networks of information (i.e. internet and world wide web), personal computers, computer filing systems, human computer interaction, visual displays, and so on.\nThe problems of information overload, or information explosion, are the same problems we witness in the context of clinical data review and sensemaking that a DMC is tasked with, or teams that have to review clinical study reports and submission dossiers,\nQuoting (Wildfire et al, 2018) \"sheer volume of data reported threatens to lose clinically relevant signals\".\nQuoting (Muetze and Friede, 2020) \"The graphical and interactive visualization of data may ease the exploration of the data and enhance the readers' understanding of the data [..]. DMC reports are no exception to this.\"\nQuoting (Buhr et al.): \"Many ISRGs include so much information in so disorganized a manner that the IDMC is overwhelmed with unnecessary and irrelevant detail; even well-organized minutiae can jeopardize comprehensibility if high-level summaries are lacking. The IDMC report must facilitate efficient review of comprehensive data through a well-designed report structure and thoughtful organization of analyses.\"\nNow, in the year 2020, we are proposing that the critical function of DSMB (as standard), provide comprehensive digital visual displays of linked quantitative information supported by intuitive (human-computer) interaction (search, query, browse, select, link, compare) to facilitate navigation and sensemaking of vital information to answer key questions. Any standalone pre-defined report will need to be supplemented as not all questions will be known in advance, and only emerge during the review process. Future reports and/or systems should be designed for this key information seeking task.\nAre we asking for too much?\nTo answer this question, we take a closer examination of what is possible now, with a specific focus on what advances in statistics, visual analytics, information science, HCI can be used to support the aims of a DMC (to identify any potential safety signals under [time, information, uncertainty, etc.] constraints) and within that task, how visual displays can be defined to answer questions to support that overall aim.\n\n\nThe use of appropriate statistical graphics is essential, from formulating the research question, initial data analysis, execution of the analysis plan, through to communicating results, recommendations and conclusions. We must not only \"get the question right\" (understand contextual subject matter) and \"get the methods right\" (technical expertise) but also \"get the message right (clear reporting).\" This is a core competency for all quantitative work.\nA lot of ground has been covered on this theme from Tukey, Tufte and Cleveland, Harrell, collaborative initiatives such as CTSpedia (https://www.ctspedia.org/do/view/CTSpedia) and PSI SIG VIS (https://www.psiweb.org/sigs-special-interest-groups/visualisation) to guidelines and recommendations [Vickers et al, 2020] and [Pocock et al 2006?, Morris et al. 2019], through to flexible tools to support statistical graphics (https://ggplot2.tidyverse.org/). However, traditional university and professional training curricula have not placed a lot of focus on effective application [Doumont]. Many researchers have to learn on the job through trial and error. This often leads to poor practice [Gordon and Finch] or the avoidance of graphics [Gelman et al.].\nWhy is this important? The role of visual displays are to ensure that relevant information (concepts, assumptions, patterns, trends, signals, and conclusions) are clearly presented and easy to interpret [Chatfield, 2002]. For this, we must understand the laws and principles of effective visual communication, such as the grammar of a (visual) language [Wilkinson]. Visualisation is more than “plotting data”; it can lead to a deeper understanding and inform next steps.\nUsing a single example to demonstrate that often the use of appropriate graphics is one of knowledge translation and assimilation, we focus on the bar charts; a commonly used graph type in medical research. Numerous articles have both demonstrated the pitfalls of using bar charts (and their extension the dynamite chart) [Clelevand, Heer, Tufte, Harrell, Vickers, Weissgerber, Vandermulebrucke], in one instance leading to a policy restricting the use of dynamite charts [http://biostat.mc.vanderbilt.edu/wiki/Main/StatisticalPolicy]. More appropriate alternatives have been advocated such as the dot plot (Clelevand, Heer, Tufte, Harrell, Wessenberger, Vandemeulebroucke 2019…). The bars often take up real estate within a chart without conveying useful information. This can also introduce clutter, hide data and sample size information, make it difficult to introduce measures of uncertainty, and also draws the eye towards false baselines. Cleveland and McGill, and follow up studies such as Heer et al. have also empirically demonstrated that dot plots are more precise for specific visual analytic tasks. Weissgerber(2015) has also demonstrated the issues from a reproducibility perspective. However, in spite of this available knowledge, the translation into standard practice has not always been achieved, with the use of barcharts and dynamite plots amongst other issues are still common (Weissgerber, 2019).\n\n\n\nThe influence of the Memex can be seen in the development of computerised systems to support (exploratory) data analysis. An incomplete timeline of statistical graphics to support exploratory data analysis have existed for a while and continuously are being improved and extended.\n\nIn 1973 the PRIM-9 system available (Tukey at al. 1973 - http://stat-graphics.org/movies/prim9.html),\n1983 Becker et al. introduced SPLOM (Becker et al.) an approach to display a matrix of scatter plots to display multivariate relationships between various measurements,\n1999 Ggobi (Swayne et al. 1999),\nMANET and Mondrian,\nStatistical programming language such as S (Chambers et al) and the follow on R (Iha)\nCorporate solutions such as SAS, Stata, etc.\n\n\n\nModern point and click graphical tools such as Spotfire, Tableau, Qlik\nWeb based applications such as Shiny to develop, bespoke, ad hoc point and click solutions\nReproducible notebooks and documents such as R markdown , Jupyter\n\nOutside of statistics and data analysis tools, we have at our disposal other technologies.\n\nStandard digital document readers such as Adobe Acrobat which have options to search (for keywords) and browse across table contents, pages, page numbering, etc.\nPDF digital documents can have hyperlinks to internal and external references.\nWe also have interactive documentation formats such as html, markdown, bookdown, javascript, which further facilitate interaction.\nJavascript libraries such as D3.js, React.js, etc.\nWe have convenient javascript wrappers to simplify the development of web based applications like shiny and plotly.\n\n\n\n\nAs stated, the problem it seems is not just one of introducing better structured reports or more visual displays. It is also not one of tool availability. It is also not the availability of literature and knowledge on information seeking, visual analytics and effective statistical graphics; see the following comprehensive reviews and overviews in these disciplines (Munzer 2014, Hullman 2019, Vanderplas, Cook and Hofmann 2020 ……..).\nThere is an element of knowledge translation and assimilation. But we should also be mindful that more interactivity and more visuals today may become tomorrow’s problem. Introducing interactivity and more visual displays thoughtlessly will not be a panacea. On the perils of interaction, as Wang et al. highlight: \"We have observed some visual designers getting carried away with packages that contain many interactivities and features, which left reviewers overwhelmed\". And on the quality of visual display quality, we refer to Gordon and Finch (2014): \"Statistician heal thyself: have we lost the plot?\", for an empirical assessment on the quality of visual displays in scientific journals.\nA recent set of papers highlight the crux of the problem and point to a future direction. Focusing on clinical data review, we also have numerous examples of this applied in practice, especially on the focus of clinical safety data review (Wang et al. 2020a, Wang et al. 2020b, Wildfire 2018, Muetze and Friede, 2020).\nWang et al. 2020a outline how interactive visual displays could support safety review. Safety reviews are iterative switching from overview to details. Wildfire et al. 2018 present an overview of a safety explorer suite. This is a collection of tools for the review of clinical trial safety developed in javascript (www.javascript.com) based visualisation libraries such as D3.js (Bostock et al., 2011).\nThis collection of papers utilize interactive data visualisation tools or interactive reports designed for this purpose (safety review). The modules contain a mixture of interactive functionality such as selecting, filtering, sorting and linking. Extending the work of Wildfire, Muetze 2020 described how this interactive suite of tools could supplement safety review for a COVID DMC.\nThese publications show promise, but what is going on here beyond more visual displays and introducing interactivity? What is going on is an implicit recognition that the task of the DMC is one of a collaborative, question and answer, information seeking, pattern identification / recognition and dialogue to identify emerging safety signals. They are applied examples of the information seeking mantra in action (Shneiderman, (1996) \"Overview first, zoom and filter, then details-on-demand\".\n\n\n\nThe DMC requires both a report (overview) and flexibility (zoom and filter, then details on demand) to further navigate available data (information). That is, there is an implicit recognition that the task at hand is not supported completely by a static, pre-specified report that standard DMC reports were designed for. Further clues can be found in the literature such as Bohr, with appeals for teams to be flexible, reports to evolve over the course of a study, for all data to be available, but to balance \"information overload\".\nFrom Buhr: \"Effective and efficient responsiveness to IDMC reporting needs is best addressed by an ISRG that combines expertise in statistics and programming, collaborates with sponsor and IDMC clinicians to develop an adequate clinical understanding of the trial, and maintains flexibility to modify the IDMC report content on an ongoing basis to respond to requests from the IDMC as they arise.\"\nAs Wang et al, 2020b, state - the design process should \"puting end-user needs first\".\nTherefore, what we need are solutions that reflect this task. The purpose (why) to ensure there are no emerging safety signals, to exhaustively explore the available data to ensure no signals exist, and to provide recommendations on next actions (to carry on, to stop, to adapt, etc.) i.e. the task. A successful DMC (the users) review can then be measured by whether the team has confidently made an informed decision that a signal(s) exists or not by addressing a series of predefined or ad-hoc questions. That no signals have been missed or overlooked. Task success can be evaluated by how teams navigate information, fostering collaboration with DMC members to arrive at a common understanding.\nThis revelation gets to the heart of the problem; that is, DMC reports are not designed to support the task of the DMC. The roles of the DMC are both as reviewers and detectives. The report should help the DMC answer the main questions to understand if there are emerging safety signals. Questions such as:\n\nIs there an imbalance?\nWas it already there at baseline?\nDoes it show meaningful relations across parameters/domains?\n\nOften the review generates more questions that have not been captured in the report (Buhr et al. ). In other words, the report is not designed to follow the workflow of the reviewers (the DMC members) within the closed session.\nDMC reports and the data displayed within are not designed to answer the questions the DMC may ask, those of signal detection. Standard DMC reports are often designed to display how data was collected and organized in the database. This is irrelevant to the DMC.\nOften displays are picked from the statistical analysis plan (SAP) tables, listings and figures (TFLs) which are geared toward a different purpose (if at all). In addition, the format and aesthetics are often not pleasing (ugly and/or not enough figures, poorly designed tables, etc). To compound the problems faced by DMC reviewers further, reports may not be structured, may not have a table of contents, outputs may have obscure identifiers such as T001.rtf, pages may not be numbered, etc (see Wittes, Buhr, etc. for further details).\nThe purpose of a DMC report is different to that of a clinical study report. As common place, DMC reports however follow a minimal structure which mimics that of an abbreviated clinical study report appendix. Disposition, demographics, safety (AEs, labs, commends, etc.). TLFs of descriptive statistics by domain and measurement dominate sprinkled potentially with some graphics. Depending on the study design, tables may cover many pages, treatment arms may also paginate across many pages. Therefore the detective work becomes more challenging, as comparisons have to be made across pages both for timepoints, parameters, and possibly treatment comparisons.\nA clinical study report is designed to provide a comprehensive overview of the final completed study. A DMC report is also different from the array of regulatory documents for a dossier to demonstrate efficacy and safety for a regulatory filing. The purpose of the CSR or dossier is to provide a complete, accurate and transparent summary of the compound and study. The study will typically be complete, the data cleaned, and sufficient analysis by the study team familiar with the study is complete.\nAlternatively for the DMC, the study is ongoing, often the data is a mixture of cleaned and uncleaned at the time of the DMC. A data cut will occur to clean data as far as possible, but to ensure the latest information is available, often additional data that has not gone through a cleaning process could be included.\nAlso, throughout the lifecycle of the DMC, new data is added for each DMC. More information is added for each meeting. This aspect is also important for identifying emerging trends.\nTo go back to the purpose of the DMC report, it is for the detection and identification of emerging safety throughout the lifecycle of a study. The report should facilitate this detective work.\nTherefore, by putting the user, the DMC, at the heart of the design, what could an intuitive, interactive, fit for purpose dmc report look like? What components and parts exist now, and what do we need to develop?"
  },
  {
    "objectID": "posts/modern-tools/modern-dmc.html#towards-more-useful-data-displays-for-dmcs",
    "href": "posts/modern-tools/modern-dmc.html#towards-more-useful-data-displays-for-dmcs",
    "title": "Don’t we just need to have more visualisations?",
    "section": "Towards more useful data displays for DMCs",
    "text": "Towards more useful data displays for DMCs\nAs argued in the previous section, the purpose of the DMC report is facilitating pattern recognition and identification. The detection of patterns are driven by answering specific questions; questions that look at the study as a whole and then drill down to specifics.\nWhat is possible now? In this section we argue with a change in perspective, a lot can be achieved with the tools and knowledge available to us.\nAlso, we want to avoid the issue of novelty. Focusing solely on novelty is not a guaranteed sign of progress. It can be argued that by doing something new, anything, to fix a problem, can lead to the problems of tomorrow. We want to be mindful of this, therefore careful design and evaluation of new proposals and solutions would be required.\nData quality, content selection, report structure, visual displays and interactivity, should follow the principles of good design, interactivity, human computer interaction, statistical graphical and visual information/analytics. A follow on principle is based in ethics. That is personnel should be qualified with appropriate knowledge, skill and experience to design, develop and implement any solutions.\nThis relates to the principal of do no harm, or as Andrew Vickers sharply phrased it:\n\n“A mistake in the operating room can threaten the life of one patient. A mistake in statistical analysis or interpretation can lead to hundreds of early deaths. So it is perhaps odd that, while we allow a doctor to conduct surgery only after years of training, we give SPSS to almost everyone.” A. Vickers\n\nWe therefore propose well understood and proven solutions that can be executed by qualified personnel. This may seem like a tall task, but a lot of knowledge, technology and best practice is available as a guide. In the following section we then allude to what could the future look like?"
  },
  {
    "objectID": "posts/modern-tools/modern-dmc.html#purpose",
    "href": "posts/modern-tools/modern-dmc.html#purpose",
    "title": "Don’t we just need to have more visualisations?",
    "section": "Purpose",
    "text": "Purpose\nAs stated, the purpose of the report is to help answer questions. More specifically the purpose of the report is to answer questions to determine if safety signals exist. This is a pattern identification and recognition task. More specifically, this could be defined as an information seeking task (Marti Hearst, Ben Schneiderman, Tamara Munzer, John Tukey, Edward Tufte, etc… ).\nAt the heart of the task is a report. This is a computer (or printed) based document in the form of words, data, tables, figures and listings. The task of the DMC is to review this document with the goal to not to miss any true safety signal. DMC reports are representations of clinical study data that are designed to help the DMC carry out tasks more effectively. Implicitly, the DMC act as \"the humans in the loop\" of a wider system including sponsors, CROs, etc, often requiring additional details to adequately complete the task (i.e. additional data and analyses, checks on data quality, additional context, etc.).\nThey need the details\n\nthe DMC may not know exactly what questions to ask in advance\nthey may need support for ongoing exploratory analysis\nthey need tools to speed up through human-in-the-loop \"visual\" data analysis\npresentation of known results\nstepping stone towards automation: refining, trust building\nNot to overlook a safety signal, not to under-estimate a signal either.\nBalance benefit with risk.\n\nAn evaluation of a well designed system is one that ensures recall (all signals) but under constraints (precision) such as time and information.\n\nPlanning\nDuring the planning and design of the DMC, it is important to capture enough information about the task at hand.\n\nHow are questions and requirements collected and used to drive the design of the report, and the displays that make up the report?\nAre the requirements of the DMC members considered?\nAre the technological needs taken into account? Multiple displays, monitors, print outs, supplemental data review systems?\nDo the DMC have access to all data, or has a selection been provided (and by whom makes the decision to filter the data).\nIs too much data provided in an unstructured way?\n\nThis points to typical planning. Start at the beginning - answer the five Ws (and the h).\nThis will not be a general, one size fits all solutions. As clinical studies vary in design, therefore how we report those studies, will also vary and require different needs. Therefore, the planning aspect is vital to capture and analyse these planning questions.\n\nWhy: safety, efficacy, benefit-risk, etc… (purpose of the DMC)\nWhat: evidence is available\nWho: Who are the reviewers (experience, needs, etc.).\nWho are the audience and what are their skills ,experience and agility to use new tools.\n\nSkills and experience.\nWhat are their needs?\nWho is responsible for what (i.e. driving new technology)?\n\nWhere: - Virtual, F2F, both. technology available. Capture all constraints.\nWhen - timelines, timing of meetings, etc.\nHow:"
  },
  {
    "objectID": "posts/modern-tools/modern-dmc.html#design",
    "href": "posts/modern-tools/modern-dmc.html#design",
    "title": "Don’t we just need to have more visualisations?",
    "section": "Design",
    "text": "Design\nAt the heart of good design is a clear purpose (why) and vision (what).\nIt is only from the problem domain that we can ascertain if a layout may be better suited and easier to understand than others. Independently of the subject, the purpose should always be centered on explanation and unveiling, which in turn leads to discovery and insight.\nIteration over the problem and solution spaces.\nDesign - pen and paper first. don't commit to solutions and lay down the tracks that are harder to unpick later.\nVisual design may be based on construction rules, design dogma or aesthetics, but all these points are neither necessary nor sufficient criteria for a successful design – but certainly a good point to start off.\nInteractive displays encourage and facilitate exploration through searching, browsing, etc. A good powerpoint presentation is a linear document, a report that is well structured could allow for non-linear digestion. But even standard digital reader tools (Adobe PDF reader) allow browsing, table of contents, hyperlinks, searching, etc. If documents are provided digitally, ensure hyperlinks to allow the reviewer to search and browse across the document, potentially provide high resolution displays (more than one?) so that different parts of the report can be viewed simultaneously. All of these solutions indicate a design choice that can be incorporated into the solution.\nMilton Glaser puts it this way: \"… All design basically is a strange combination of the intelligence and the intuition, where the intelligence only takes you so far and than your intuition has to reconcile some of the logic in some peculiar way. …\"\n\"He who is ashamed of asking is afraid of learning\", says a famous Danish proverb. A great quality to anyone doing work in the realm of Information Visualization is to be curious and inquisitive. Every project should start with a question. An inquiry that leads you to discover further insights on the system, and in the process answer questions that weren't even there in the beginning. This investigation might arise from a personal quest or the specific needs of a client or audience, but you should always have a defined query to drive your work.\n\nQuestions\nGood visualisations begin with a question. This could be a question to explore further or to explain, but a question nonetheless. For example, I want to determine if there is an imbalance between treatments for any safety parameters. This is an exploratory question that indicates a search across safety outcomes, comparing incidences or measurements between treatments. This exploration may lead to follow up questions. For example, if a potential imbalance is discovered, the natural question could be, what is driving this, is it treatment or some other characteristic?\n\n\nGood visualisations provide comparisons.\n\n\nWhy use visual displays?\nVisual communication is one of the most effective channels for displaying quantitative information, and as with written communication, it is also important to be clear and accurate. Effective visual communication means using the visual channel to deliver the right information or messages clearly and concisely. By following the right graphical principles, we can better understand data, highlight core insights and influence decisions toward appropriate actions. Without it, we can fool ourselves and others and pave the way to wrong conclusions and actions.\n\n\nWhile numerous literature, guidance and solutions exist how do we put this in practice in an accurate, transparent and reproducible way? This brings us back to the aims of each visual display. The question.\n\n\nUsing visual representations of data, we can replace cognition with perception.\n\n\nWhy depend on vision?\nThe human visual system is high-bandwidth channel to brain\n\noverview possible due to background processing\nsubjective experience of seeing everything simultaneously\nsignificant processing occurs in parallel and pre-attentively\n\n\n\n\n\nWhy representations of all the data?\nSummaries \"can\" lose information, details matter\n\nconfirm expected and find unexpected patterns\nassess validity of statistical model\n\n\n\nMove from top level to low level details\n\n\n\n\nWhy statistical graphics?\n\nto help with presentation to a broad audience of varying levels of quantitative knowledge (make complex more understandable)\nto help with diagnostics and assumption checking - is the model or aggregation (boxplot) hiding something (bi-modal distributions or outliers)\nexploration - to gain insights and deduce properties and relationships\ncontext - to understand issues and gaps in (dirty) data (i.e. missingness patterns, measurement error, etc.). plotting is essential to find, understand and resolve issues and artifacts and errors in data.\n\n\n\nWhy focus on tasks and effectiveness?\nEffectiveness requires match between data/task and representation\n\nset of representations is huge\nmany are ineffective mismatch for specific data/task combo\nincreases chance of finding good solutions if you understand full space of possibilities\n\n\n\n\n\nWhat counts as effective?\n\nnovel: enable entirely new kinds of analysis\nfaster: speed up existing workflows\n\n\n\nThis goes back to task / purpose - information seeking (exhaustive - recall https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Recall), with sufficient precision to management information overload.\n\n\n\n\nHow to validate effectiveness?\n\nmany methods, must pick appropriate one for your context"
  },
  {
    "objectID": "posts/modern-tools/modern-dmc.html#what-resource-limitations-are-we-faced-with",
    "href": "posts/modern-tools/modern-dmc.html#what-resource-limitations-are-we-faced-with",
    "title": "Don’t we just need to have more visualisations?",
    "section": "What resource limitations are we faced with?",
    "text": "What resource limitations are we faced with?\nDesigners must take into account three very different kinds of resource limitations: those of computers, of humans, and of displays.\n\n\n\ncomputational limits\n\nprocessing time\nsystem memory\n\n\n\n\n\nhuman limits\n\nhuman attention and memory\n\n\n\n\n\ndisplay limits\n\npixels are precious resource, the most constrained resource\ninformation density: ratio of space used to encode info vs unused whitespace\n\ntradeoff between clutter and wasting space, find sweet spot between dense and sparse\n\n\n\n\n\n\nPrinciples for encoding data\nexpressiveness principle\n\nmatch channel and data characteristics\n\neffectiveness principle\n\nencode most important attributes with highest ranked channels (cleveland and mcgill)\n\n\n\n\n\n\nWhy design analyze (problem and solution space)?\n\n\nWhat, Why, and How\n\n\nimposes structure on huge design space\n\nscaffold to help you think systematically about choices\nanalyzing existing as stepping stone to designing new\nmost possibilities ineffective for particular task/data combination\n\n\n\n\nData encoding\n\nlinking, aggregation, statistics, representations, etc.\nraw data\nderived data\naggregated data\ncomparisons\nnumbers, colours, shapes, lines, points, areas, position, tilt\n\nCleveland and Mcgill ranking\n\n\n\n\nTask abstraction\n\ndiscover distribution\ncompare trends\nlocate outliers\nbrowse topology\n\n\n\nActions\n\nAnalyse\nSearch\nQuery\nBrowse\n\n\n\nTargets\n\nAll data\n\ntrends\noutliers\nfeatures\n\nAttributes\n\none outcome vs multivate outcomes\n\nLinked data"
  },
  {
    "objectID": "posts/modern-tools/modern-dmc.html#interactivity",
    "href": "posts/modern-tools/modern-dmc.html#interactivity",
    "title": "Don’t we just need to have more visualisations?",
    "section": "Interactivity",
    "text": "Interactivity\n\n\nOften interactivity is spoken to describe different concepts: (human computer) interactivity and dynamic (animation) displays. A dynamic output or display is one that uses animated / rotating plots to often visualize high dimensional (continuous) data. When we refer to interactivity, we refer to the process of human-computer interaction. Interactive outputs are referring to outputs that enable human computer interaction to change selections and parameters quickly, or to navigate within and across outputs.\n\n\nInteractive displays encourage and facilitate exploration through searching, browsing, etc. A good powerpoint presentation is a linear document, a report that is well structured could allow for non-linear digestion. But even standard digital reader tools (Adobe PDF reader) allow browsing, table of contents, hyperlinks, searching, etc. If documents are provided digitally, ensure hyperlinks to allow the reviewer to search and browse across the document, potentially provide high resolution displays (more than one?) so that different parts of the report can be viewed simultaneously. All of these solutions indicate a design choice that can be incorporated into the solution.\n\n\nTaken to the extreme a well structured report with improved navigation tools, can facilitate this better. Within outputs /a single page, information can be navigated.\n\n\nWith good HCI it is important to have the users in control. The cockpit control metaphor. Important information can be accessed and found (not hidden by poor designs).\n\n\nHere we are not indicating a wholesale transformation from printed reports to advanced interactive systems. Even carefully designed printed reports can become user friendly if we consciously focus on how the user will interact with the document. For example, including a table of contents, page numbers, descriptive titles, references and cross references, context, data sources, etc.\n\n\nInteractivity can be defined as verbs that capture the action with the system:\n\nSelect\nSort\nFilter\nJoin\nDisplay\n\n\n\nThere are numerous elements to interactivity\n\nselection (of outcome, parameter, subgroup, patient)\n\nfind all patients with event\ndisplay all patients with event\nonly show AEs with 10% incidence rates\n\nhighlighting\n\nsubgroup, patient, outcome, etc.\n\nquery\n\ninformation on objects\n\nmodification\n\nchange parameters and models\n\nlinking\n\nlink between selection and highlighting\n\n\n\n\nPrinciples\n\nImportance on making it intuitive for all users.\nTechnology supports and does not get in the way\n\n\n\nMany ways this could be facilitated now, from the low tech examples\n\nbasic printed reports could have a table of contents, page numbering, clear output titles and descriptions, and a coherent structure.\nA DMC meeting could provide more than one monitor to help compare different outputs simultaneously.\nEven better touchscreen monitors to help with the interaction.\n\n\n\n\nInteractivity is key\nAs defined by Ben Shneiderman, Stuart K. Card and Jock D. Mackinlay, \"Information Visualization is the use of computer-supported, interactive, visual representations of abstract data to amplify cognition\". This well-known statement highlights how interactivity is an integral part of the field's DNA. Any Information Visualization project should not only facilitate understanding but also the analysis of the data, according to specific use cases and defined goals. By employing interactive techniques, users are able to properly investigate and reshape the layout in order to find appropriate answers to their questions. This capability becomes imperative as the degree of complexity of the portrayed system increases. Visualization should be recognized as a discovery tool.\n\n\n\n\nA note on data management and interactivity\nLinked data is required to facilitate interactivity across outputs / measurements.\nLinking can come in many forms:\n\nA hyperlink from a table of contents to a specific output.\nA hyperlinked cross reference between table and figure\n\n\n\nLinked summary / aggregated measurements\nPatient linked to measurements\nLinks between related parameters or different aggregations of the same parameter.\n\n\n\nA note on interactivity and reproducibility\n\n\nAre we computing analyses on the fly, or are we rendering pre-computed analyses, where interactivity is a navigation tool. This has a link to analysis results data sets (the graph principle paper) or LEGEND paper.\nFrom Harrel: Definitely, since I'm really referring to partial interactivity, e.g. drill down to see more information. And one of our hotshot R developers showed me how to create an RMarkdown html report that has a click box in it that allows the user to view printable static graphs vs. semi-interactive graphs when the statistician has dual code chunks to handle the two tasks (e.g., one chunk calling ggplot and the other calling plotly).\n\n\nPrinciples for building tools with interactivity\n\nLeave out any task that humans can do better than computers.\nLeave out any task that's associated with an important skill that would be lost if we allowed computers to do it for us.\nLeave out any feature that is ineffective.\nAdd features to perform tasks that computers can do better than humans.\nAdd features to perform tasks that humans do not benefit from performing in some important way.\nAdd features that are recognized as useful by skilled data analysts, but only after considering the full range of implications.\nNever add a feature simply because it can be added or because it would be convenient to add.\nNever add a feature merely because existing or potential customers ask for it.\nNever add a feature simply because an executive wants it.\nNever design a feature in a particular way because it is easier than designing it in a way that works better.\nNever design a feature that requires human-computer interaction without a clear understanding of the human brain—its strengths and limitations.\nNever design a feature that that requires human-computer interaction that forces people to think and act like computers."
  },
  {
    "objectID": "posts/modern-tools/modern-dmc.html#report-structure",
    "href": "posts/modern-tools/modern-dmc.html#report-structure",
    "title": "Don’t we just need to have more visualisations?",
    "section": "Report structure",
    "text": "Report structure\nThe report structure is a mixture of Sponsor guidelines or standards and the influence of the ICH structure for clinical study report. Display by domains.\n\n\nThis leads to a natural question, is the purpose of the DMC report a typical report, or should the focus be something else, with a side effect that the data can be captured as a report for prosperity?\n\n\n\nCentral graph (one or very few) as start-and-return point(s) (simple overview(s)), \"linked\" to more specific graphs for digging deeper.\n\n\nDeep and wide, focus and context, detail and summary, trees and forest are all expressions that capture these two fundamental perspectives from which we should view our data if we wish to understand it. Errors are routinely made when we dig into a specific issue and form judgments without understanding it in context. Exploring data from every possible angle provides the context that's necessary to understand the details. It keeps us from getting lost among the trees, wandering from one false conclusion to another, fools rushing in and rushing out, never really knowing where we've been.\n\n\n\n\nGroup vs individual data\nShow related data together (multivariate plots; show baseline in context; comprehensive patient profiles; ...)\nThe role of plots \"vs\" tables \"vs\" listings…\n\n\n\n\nStructure of an ideal report\nAn ideal report and/or system should follow the reviewer's workflow in addressing these questions:\n\nStart from central overview, then dig back and forth (top-down ↔︎ bottom-up) into notable points or questions.\nEspecially, oscillating (a) between group level and individual level, (b) between post-treatment and pre-treatment data, and (c) across parameters and domains. [And potentially (d) between safety and efficacy, for benefit/risk tradeoff?]\nOf special interest are \"outliers\", and the assessment of time. E.g., how long did an abnormality persist? Did its timing relate to other abnormalities and/or to treatment, conmeds etc?\nThe report should foster collaboration, facilitate dialogue and discussion, enable detective work, improve understanding, improve communication.\n\nThis relates back to the information seeking mantra: \"Overview first, zoom and filter, then details-on-demand\".\n\n\n\n\n\nContent\nThe content of the report is typically disposition, demographics and demographics and safety. Efficacy where necessary for benefit-risk assessments.\n\n\nDue to issues around constraints, information overload and trial integrity - not all data is provided (as standard).\n\n\nOpen session - treatments are hidden. Closed sessions treatments may be masked.\n\n\nOutput types (by domain)\n\nTables\nListings\nFigures\n\n\n\nData / outputs\n\nGroup vs individual data\n\nCurrent problems\n\nThese outputs may not be structured.\nMay not have a table of contents.\nMay have obscure identifiers such as T001.rtf, etc.\n\n\n\n\n\nContext\n\n\nContext comes in many forms. Institutional knowledge. Experience. Open session. Benefit risk. Prior knowledge. Previous studies. How to systematic it for improvement.\n\n\n\nDomain knowledge\n\n\n\n\n\nWorkflow\n\n\nThe workflow could be argued is shared across sponsor, CRO and DMC (adds to the challenge)\n\n\nThis division of labour adds to the challenge, and requires trust between different groups, functions, stakeholders, etc.\n\n\nAs highlighted by Chatfield, a pragmatic workflow for an analysis could resemble the following\n\nExploring context\nCollecting necessary data - valid\nCarrying prelim examination of data\nFormulating an appropriate model and being willing to revise it\nChecking predictive accuracy\nTaking active steps to avoid trouble\nCommunicating results clearly\n\n\n\nHow does such a workflow for EDA (detective work) translate in to this cross function / group / stakeholder task?\n\n\n\n\n\nConstraints\n\nTimebound\nCleanliness of data\nBlinding\nResources and skill sets (of DMC, of CRO, of Sponsor)\nDomain knowledge and experience (of DMC, of CRO, of Sponsor)\nHardware - monitors / print outs\nSecurity / integrity of data\nData availability\nData cleanliness"
  },
  {
    "objectID": "posts/modern-tools/modern-dmc.html#statistical-graphics",
    "href": "posts/modern-tools/modern-dmc.html#statistical-graphics",
    "title": "Don’t we just need to have more visualisations?",
    "section": "Statistical graphics",
    "text": "Statistical graphics\n\n\nPlot types\n\nChange from baseline; spaghetti plots of abnormals only (to judge time aspect without overcrowding); …"
  },
  {
    "objectID": "posts/modern-tools/modern-dmc.html#ethics",
    "href": "posts/modern-tools/modern-dmc.html#ethics",
    "title": "Don’t we just need to have more visualisations?",
    "section": "Ethics",
    "text": "Ethics\nThere is an ethical element to patients, to society, etc to get this right."
  },
  {
    "objectID": "posts/modern-tools/modern-dmc.html#statistics",
    "href": "posts/modern-tools/modern-dmc.html#statistics",
    "title": "Don’t we just need to have more visualisations?",
    "section": "Statistics",
    "text": "Statistics\nAggregate statistics, descriptive statistics, graphics, etc. are all statistical models that come with assumptions. Make this conscious through the design. Displaying a box plot assumes the data is not bimodal. Displaying a bar chart assumes the data is anchored at baseline. Displaying a scatter plot implicit assumes we are looking for an association between Y and X.\nThe role of statistical significance: none\nWhat types of summaries\nWhat types of comparisons."
  },
  {
    "objectID": "posts/modern-tools/modern-dmc.html#data-management",
    "href": "posts/modern-tools/modern-dmc.html#data-management",
    "title": "Don’t we just need to have more visualisations?",
    "section": "Data management",
    "text": "Data management\n\nData models\nLinking\nAnalysis data models\nData structures\n\n\n\nData cleaning"
  },
  {
    "objectID": "posts/modern-tools/modern-dmc.html#questions-to-be-resolved",
    "href": "posts/modern-tools/modern-dmc.html#questions-to-be-resolved",
    "title": "Don’t we just need to have more visualisations?",
    "section": "Questions to be resolved",
    "text": "Questions to be resolved\n\nHow do you view the role of the report?\nHow do you see you and DMC in the role of designing / defining the report?\nDo you think the standard should be digital (that can be printed hard copy)?\nDo you think the standard should be hyperlinked (between outputs, with ToC)\nNeed specialist companies with the qualified personal to do this - ISRG (who funds?)\nWith figures comes a higher standard to implement correctly."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "My notes",
    "section": "",
    "text": "Analysis plans\n\n\n\nsap\n\n\nppdac\n\n\nexplore\n\n\ngdsp\n\n\n\nRough notes on analysis plans for exploratory investigations\n\n\n\n\n\n\nDec 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIDA for regression\n\n\n\nida\n\n\nnotebook\n\n\nregression\n\n\nanalysis\n\n\n\nGuidance on conducting initial data analysis in a reproducible manner in the context of intended regression analyses.\n\n\n\n\n\n\nNov 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDon’t we just need to have more visualisations?\n\n\n\ndmc\n\n\nnotes\n\n\nmodern tools\n\n\ndata viz\n\n\nhci\n\n\n\nUnfiltered and to be processed notes supporting the writing of the 21st century DMC paper\n\n\n\n\n\n\nOct 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLessons from a company wide data visualization initiative\n\n\n\ngraphics\n\n\nards\n\n\nevc\n\n\nslides\n\n\n\nPresenting to efspi/PSDM Meeting on Data Visualisation\n\n\n\n\n\n\nApr 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInitial data analysis\n\n\n\ngood practice\n\n\nida\n\n\ndata analysis\n\n\n\nTen simple rules to help provide a better foundation for data analysis.\n\n\n\n\n\n\nDec 17, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis results data sets\n\n\n\nards\n\n\nFAIR\n\n\ndata engineering\n\n\ndata science\n\n\ndata stewardship\n\n\n\nRethinking what the data analysis target is.\n\n\n\n\n\n\nNov 17, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSix simple survival tips\n\n\n\nKM plots\n\n\nvisualisation\n\n\nevc\n\n\n\nPresentation at PSI 2022 conference.\n\n\n\n\n\n\nJul 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThoughts on exploratory data analysis\n\n\n\ngdsp\n\n\ngood practice\n\n\ndata science\n\n\ncritical thinking\n\n\n\nCan developing critical thinking, broader than statistics issues, help improve data analysis practice, especially in the exploratory setting?\n\n\n\n\n\n\nMar 10, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStop shouting and turn off the caps lock\n\n\n\nline plots\n\n\ntransparency\n\n\nemphasis\n\n\nevc\n\n\n\nSimple and practical solutions to tone down your next graph.\n\n\n\n\n\n\nDec 17, 2021\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Mark Baillie",
    "section": "",
    "text": "Mark Baillie is a member of the Advanced Methodology and Data Science group at Novartis. He focuses on methodology to support drug development, working on a variety of internal and external initiatives to improve the reporting of clinical trials. These include effective visual communication, initial data analysis, DMC reporting, analysis results standards, and data challenges. Mark is a member of the Stratos initiative and the PSI visualisation special interest group."
  },
  {
    "objectID": "about.html#bio",
    "href": "about.html#bio",
    "title": "Mark Baillie",
    "section": "",
    "text": "Mark Baillie is a member of the Advanced Methodology and Data Science group at Novartis. He focuses on methodology to support drug development, working on a variety of internal and external initiatives to improve the reporting of clinical trials. These include effective visual communication, initial data analysis, DMC reporting, analysis results standards, and data challenges. Mark is a member of the Stratos initiative and the PSI visualisation special interest group."
  },
  {
    "objectID": "about.html#robot-bio",
    "href": "about.html#robot-bio",
    "title": "Mark Baillie",
    "section": "Robot bio",
    "text": "Robot bio\nExperienced consultant and methodologist with a demonstrated track record of delivering projects in industry, civil service, and academia. Skilled in statistical thinking, data analysis and modelling, data engineering, machine learning, visualization, effective communication, and project leadership. Written by a robot."
  },
  {
    "objectID": "posts/ards/ards.html",
    "href": "posts/ards/ards.html",
    "title": "Analysis results data sets",
    "section": "",
    "text": "Barros, J.M., Widmer, L.A., Baillie, M. et al. Rethinking clinical study data: why we should respect analysis results as data. Sci Data 9, 686 (2022). https://doi.org/10.1038/s41597-022-01789-2"
  },
  {
    "objectID": "posts/ida-regression/index.html",
    "href": "posts/ida-regression/index.html",
    "title": "IDA for regression",
    "section": "",
    "text": "Paper under review\nThe focus of this report is to provide guidance on conducting initial data analysis in a reproducible manner in the context of intended regression analyses"
  },
  {
    "objectID": "posts/gdsp/gdsp.html",
    "href": "posts/gdsp/gdsp.html",
    "title": "Thoughts on exploratory data analysis",
    "section": "",
    "text": "Good Data Science Practice: Moving Toward a Code of Practice for Drug Development: Moving Toward a Code of Practice for Drug Development, April 2022. Statistics in Biopharmaceutical Research. DOI:10.1080/19466315.2022.2063172\nThere is growing interest in data science and the challenges that scientists can solve through its application. The growing interest is in part due to the promise of “extracting value from data.” The pharmaceutical industry is no different in this regard reflected by the advancement and excitement surrounding data science. Data science brings new perspectives, new methods, new skill sets and the wider use of new data modalities. For example, there is a belief that extracting value from data integrated from multiple sources and modalities using advances in statistics, machine learning, informatics and computation can answer fundamental questions. These questions span a variety of themes including disease understanding, drug and target discovery, and trial design. By answering fundamental questions, we cannot only increase knowledge and understanding but more importantly inform decision making; accelerating drug development through data-driven prioritization, increasingly precise and accurate measurements, optimized trial designs and operational excellence. However, with the promise of data science, there are obstacles to overcome, especially if data science is to live up to this promise and deliver a positive impact. These obstacles include consensus on the definition of data science, the relationship between data science and existing fields such as statistics and computing science, what should be involved in the day-to-day practices of data science, and what is “good” practice. In this article, we cover these themes, highlighting issues with scientific practice from five perspectives and argue how advances in data science will not be immune, especially exploratory, investigative, and innovative activities. We propose a definition of data science as a coming together but also a refocusing of established disciplines leading to a framework for good practice. In doing so, we aim to begin a dialogue on good data science practice in the context of drug development, where there is no industry view or consensus."
  },
  {
    "objectID": "posts/ida/ida.html",
    "href": "posts/ida/ida.html",
    "title": "Initial data analysis",
    "section": "",
    "text": "Baillie M, le Cessie S, Schmidt CO, Lusa L, Huebner M, et al. (2022). Ten simple rules for initial data analysis PLOS Computational Biology 18(2): e1009819. https://doi.org/10.1371/journal.pcbi.1009819\nWe have developed 10 rules to explain IDA and the benefits of adopting IDA in practice. The 10 rules are based on extensive experience with research projects, collaborations with domain experts, and discussions among an international group of applied statisticians. However, an understanding of IDA is important not only for statisticians but for all researchers who analyze data (e.g., epidemiologists, computational biologists, bioinformaticians, machine learning experts) or consume the outputs of data analysis (e.g., domain experts). These rules are applicable for small and large collaborative research projects, whether for primary data collection or repurposing an existing data set, and for data of all shapes and sizes including “big data.” A caveat for these 10 rules is that IDA is not an off-the-shelf cookbook. As with all good practice, IDA strategies require careful thinking and design based on the problem and context, not the preference of the analyst. Remember, “there are no routine statistical questions, only questionable statistical routines (David R. Cox)”"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Mark Baillie",
    "section": "",
    "text": "Attribution 4.0 International\n=======================================================================\nCreative Commons Corporation (“Creative Commons”) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an “as-is” basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.\nUsing Creative Commons Public Licenses\nCreative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.\n Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More considerations\n for the public: \nwiki.creativecommons.org/Considerations_for_licensees\n=======================================================================\nCreative Commons Attribution 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\n\nreproduce and Share the Licensed Material, in whole or in part; and\nproduce, reproduce, and Share Adapted Material.\n\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)\n\nnever produces Adapted Material.\n\nDownstream recipients.\n\nOffer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nNo downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\n\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\n\nretain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nindicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nindicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\n\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\nIf You Share Adapted Material You produce, the Adapter’s License You apply must not prevent recipients of the Adapted Material from complying with this Public License.\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material; and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS, IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION, WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS, ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.\nTO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION, NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT, INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES, COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n=======================================================================\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  }
]